{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import inspect\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from react_agent_system_prompts import *\n",
    "from members_details import members\n",
    "import getpass\n",
    "import os\n",
    "import shutil\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override = True)\n",
    "\n",
    "\n",
    "\n",
    "def copy_directory(src_dir):\n",
    "    dst_dir= os.path.basename(src_dir)+'new'\n",
    "    dst_dir = os.path.join(os.path.dirname(src_dir), dst_dir)\n",
    "\n",
    "    if not os.path.exists(dst_dir):\n",
    "        os.makedirs(dst_dir)\n",
    "    for item in os.listdir(src_dir):\n",
    "        s = os.path.join(src_dir, item)\n",
    "        d = os.path.join(dst_dir, item)\n",
    "        shutil.copy2(s, d)\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()\n",
    "\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from supervisor_node import make_supervisor_node\n",
    "from ore_xml_agent import ore_xml_agent_node\n",
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "from sensitivity_agent import sensitivity_agent_node\n",
    "from ore_execution_agent import ore_execution_agent_node\n",
    "from ExtendedState import State\n",
    "\n",
    "\n",
    "llm = ChatAnthropic(\n",
    "    model=\"claude-3-5-haiku-latest\",\n",
    "    temperature=0,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "main_supervisor_node = make_supervisor_node(llm=llm, state=State, members=members)\n",
    "\n",
    "main_agent_builder = StateGraph(State)\n",
    "main_agent_builder.add_node(\"supervisor\", main_supervisor_node)\n",
    "main_agent_builder.add_node(\"ore_xml_agent\", ore_xml_agent_node)\n",
    "main_agent_builder.add_node(\"sensitivity_agent\", sensitivity_agent_node)\n",
    "main_agent_builder.add_node(\"ore_execution_agent\", ore_execution_agent_node)\n",
    "\n",
    "main_agent_builder.add_edge(START, \"supervisor\")\n",
    "main_graph = main_agent_builder.compile()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ascii_representation = main_graph.get_graph().print_ascii()\n",
    "print(ascii_representation)\n",
    "\n",
    "for s in main_graph.stream(\n",
    "    {\"messages\": [(\"user\", \"What is shock applied to EUR discounting curve. After that run the ore to compute npv results.\")]}\n",
    "):\n",
    "    print(s)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from react_agent_system_prompts import ore_execution_agent_system_prompt_content\n",
    "from config_file import file_location_prompt\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from ore_xml_agent import ore_agent\n",
    "from ore_execution_agent import ore_execution_agent\n",
    "from ExtendedState import State\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override = True)\n",
    "\n",
    "\n",
    "state = State()\n",
    "state[\"messages\"] = [HumanMessage(content=\"Run the ore to compute npv results.\")]\n",
    "input_messages = {'messages': [SystemMessage(content=ore_execution_agent_system_prompt_content),SystemMessage(content=file_location_prompt)]}\n",
    "messages_list = input_messages[\"messages\"] + state[\"messages\"]\n",
    "messages = {'messages': messages_list}\n",
    "response = ore_execution_agent.invoke(messages)\n",
    "state[\"messages\"] = messages_list + response[\"messages\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ore_execution_tools import run_ore\n",
    "\n",
    "test = run_ore.invoke({\"file_path\":\"D:\\Project_H\\Examples\\Example_1\\Inputnew\\ore.xml\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ORE run completed successfully.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [1,2,3,4,5]\n",
    "while (len(test>))\n",
    "test = test[1:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ore_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
